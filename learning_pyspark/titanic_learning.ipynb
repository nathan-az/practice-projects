{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyspark_helper.util as util\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, coalesce, col, lit, regexp_extract, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .getOrCreate()\n",
    "\n",
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(\"train.csv\")\n",
    "\n",
    "# cheeky unpacking to turn column titles to lower\n",
    "df = df.toDF(*[c.lower() for c in df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration, Cleaning, and Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the count of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 891\n",
      "Column: age, num missing: 177 (% missing: 19.9%)\n",
      "Column: cabin, num missing: 687 (% missing: 77.1%)\n",
      "Column: embarked, num missing: 2 (% missing: 0.2%)\n"
     ]
    }
   ],
   "source": [
    "missing = util.print_missing(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 3/4 of \"Cabin\" data is missing (687/891). There are a total 148 unique values, so 204 of the non-missing samples are unique. There may be useful information here still (e.g. cabin area, treating A23 and A12 as equivalent). But for now, \"Cabin\" is removed.\n",
    "\n",
    "Embarked has a small amount missing. These are set these to 0 for the sake of one-hot encoding, but will have minimal effect on data. For age, a recursive tree model will be used to predict the remaining values (alternatively, simple mean could be used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that seem to offer little in terms of predictive value\n",
    "removed_features = [\"passengerid\", \"name\", \"ticket\", \"cabin\"]\n",
    "# Create a list of features\n",
    "initial_features = df.columns\n",
    "target = \"survived\"\n",
    "initial_features.remove(target)\n",
    "for remove in removed_features:\n",
    "    initial_features.remove(remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns are kept where there is some a priori reason to believe they would act as strong predictors. These include:\n",
    "Pclass, Age, Sex, SibSp, Parch, Fare, Embarked\n",
    "\n",
    "Name, PassengerId, and Ticket are omitted as well due to being largely unique values without much discernible useful information\n",
    "\n",
    "Replace missing values with 0. Since these variables are categorical and 0 is not a natural value, missing data will in essence be its own category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String features for encoding: ['sex', 'embarked']\n",
      "Numeric features: ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
      "\n",
      "-------- Columns with null values printed below --------\n",
      "Total samples: 891\n",
      "Column: age, num missing: 177 (% missing: 19.9%)\n",
      "Column: cabin, num missing: 687 (% missing: 77.1%)\n"
     ]
    }
   ],
   "source": [
    "# all string columns will be required to be encoded\n",
    "features_for_encoding = ['sex', 'embarked']\n",
    "numeric_features = ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
    "print(\"String features for encoding: {0}\\\n",
    "    \\nNumeric features: {1}\".format(features_for_encoding, numeric_features))\n",
    "df = df.na.fill(\"0\", subset=features_for_encoding)\n",
    "print(\"\\n\", \"-\"*8, \" Columns with null values printed below \", \"-\"*8, sep=\"\")\n",
    "missing = util.print_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding String/categorical features for modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one-hot transformer for Sex and Embarked is created and kept for use later on the test set. (Note this has been modularised in the helper module)\n",
    "\n",
    "Pipeline: String -> StringIndex -> OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_transformer = util.string_to_onehot_transformer(df=df, columns_for_encoding=features_for_encoding)\n",
    "df = onehot_transformer.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing age\n",
    "Age has many missing values, but is numerical but holds important information, so it is preferable not to drop it. Missing values can be imputed with the mean, but instead will be predicted using a decision tree model regressor. Since this is only to fill missing data, there will not be extensive hyperparameter tuning at this point. A quick cross-validation will indicate whether prediction to impute performs better than mean imputation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the predictors for age are vectorised. Then the decision tree regressor is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = numeric_features + [col+\"_encoded\" for col in features_for_encoding]\n",
    "age_predictors = feature_cols.copy()\n",
    "age_predictors.remove(\"age\")\n",
    "vectoriser = util.create_feature_vectoriser(df, age_predictors, \"age_predictors\")\n",
    "df = vectoriser.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the DataFrame is filtered to only train on non-null labels. Then, cross-validation is performed to check the OOF metric (RMSE) against the same metric if mean values were imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.filter(df[\"age\"].isNotNull())\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "dt_params = [{dt.featuresCol: \"age_predictors\", \n",
    "              dt.labelCol: \"age\", \n",
    "              dt.predictionCol: \"age_prediction\",\n",
    "              dt.maxDepth: 5}]\n",
    "regression_evaluator = RegressionEvaluator(predictionCol=\"age_prediction\",\n",
    "                                          labelCol=\"age\")\n",
    "\n",
    "rpart_cv = CrossValidator(estimator=dt,\n",
    "                          estimatorParamMaps=dt_params,\n",
    "                          evaluator=regression_evaluator,\n",
    "                          numFolds=5)\n",
    "\n",
    "rpart_cv_model = rpart_cv.fit(df_filtered)\n",
    "best_age_rpart = rpart_cv_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of non-null values in training set: 29.70\n",
      "Out of fold RMSE of predictions against training set: 12.78        \n",
      "RMSE of mean value against training set: 14.52\n"
     ]
    }
   ],
   "source": [
    "mean_age = df_filtered.agg(avg(col(\"age\"))).collect()[0][0]\n",
    "print(\"Mean of non-null values in training set: {0:.2f}\".format(mean_age))\n",
    "df_filtered = df_filtered.withColumn(\"mean_age\", lit(mean_age))\n",
    "evaluator = RegressionEvaluator()\\\n",
    "        .setMetricName(\"rmse\")\\\n",
    "        .setLabelCol(\"age\")\\\n",
    "        .setPredictionCol(\"mean_age\")\n",
    "mean_rmse = evaluator.evaluate(df_filtered)\n",
    "predicted_rmse = rpart_cv_model.avgMetrics[0]\n",
    "print(\"Out of fold RMSE of predictions against training set: {0:.2f}\\\n",
    "        \\nRMSE of mean value against training set: {1:.2f}\".format(predicted_rmse, mean_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OOF RMSE is lower than the mean RMSE for labeled ages, indicating that predicted ages are more accurate than the mean. This means that for samples with null age values, the predicted values will (in general) be stronger predictors than the mean. Now the model will be trained on all available age data and applied to the missing data. Then, all features for Survival are vectorised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = best_age_rpart.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"age\", coalesce(df.age, df.age_prediction))\n",
    "df = df.drop(\"age_predictors\", \"age_prediction\")\n",
    "feature_vectoriser = util.create_feature_vectoriser(df, feature_cols, \"features\")\n",
    "df = feature_vectoriser.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Columns to be used as features\n",
      "['pclass', 'age', 'sibsp', 'parch', 'fare', 'sex_encoded', 'embarked_encoded'] \n",
      "\n",
      "-------- Top 5 rows of label and vectorised features\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|[3.0,22.0,1.0,0.0...|\n",
      "|    1|[1.0,38.0,1.0,0.0...|\n",
      "|    1|(9,[0,1,4,6],[3.0...|\n",
      "|    1|[1.0,35.0,1.0,0.0...|\n",
      "|    0|[3.0,35.0,0.0,0.0...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+----+-----+-----+-------+-------------+----------------+\n",
      "|pclass| age|sibsp|parch|   fare|  sex_encoded|embarked_encoded|\n",
      "+------+----+-----+-----+-------+-------------+----------------+\n",
      "|     3|22.0|    1|    0|   7.25|(1,[0],[1.0])|   (3,[0],[1.0])|\n",
      "|     1|38.0|    1|    0|71.2833|    (1,[],[])|   (3,[1],[1.0])|\n",
      "|     3|26.0|    0|    0|  7.925|    (1,[],[])|   (3,[0],[1.0])|\n",
      "|     1|35.0|    1|    0|   53.1|    (1,[],[])|   (3,[0],[1.0])|\n",
      "|     3|35.0|    0|    0|   8.05|(1,[0],[1.0])|   (3,[0],[1.0])|\n",
      "+------+----+-----+-----+-------+-------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed(\"survived\", \"label\")\n",
    "print(\"-\"*8, f\"Columns to be used as features\")\n",
    "print(feature_cols, \"\\n\")\n",
    "print(\"-\"*8, \"Top 5 rows of label and vectorised features\")\n",
    "df.select(\"label\", \"features\").show(5)\n",
    "df.select(*feature_cols).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note AUC will be used as the evaluation metric, so thresholds are not a concern. Model will be first run with the base hyperparameters before performing random (as opposed to grid) search with 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier()\n",
    "gbt_transformer = gbt.fit(df)\n",
    "df = gbt_transformer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+--------------------+\n",
      "|label|prediction|         probability|       rawPrediction|\n",
      "+-----+----------+--------------------+--------------------+\n",
      "|    0|       0.0|[0.91398813051760...|[1.18166614054903...|\n",
      "|    1|       1.0|[0.05278475052523...|[-1.4436520151715...|\n",
      "|    1|       1.0|[0.48663789379179...|[-0.0267305771414...|\n",
      "|    1|       1.0|[0.04441291376077...|[-1.5343978119854...|\n",
      "|    0|       0.0|[0.88634908728346...|[1.02698964775194...|\n",
      "+-----+----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Incorrect predictions: 91\n",
      "AUC: {0:.2f} 0.9542655972049133\n"
     ]
    }
   ],
   "source": [
    "df.select(*[\"label\", \"prediction\", \"probability\", \"rawPrediction\"]).show(5)\n",
    "print(\"Incorrect predictions:\",df.filter(df.label != df.prediction).count())\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print(\"AUC: {0:.2f}\",evaluator.evaluate(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has very high AUC. Even with the default threshold of 0.5, it is only inaccurate for 91 rows... But it is obviously overfitting. Time for cross validation and random parameter search. The final parameters will be those which maximise the OOF metric (AUC).\n",
    "\n",
    "Note that below, the paramGrid is not actually a grid and only offers one option per hyperparameter. This is because the intention is to perform random search rather than grid search. There may be a more elegant solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few temporary functions are defined to generate hyperparameter values from the intended distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_stepSize():\n",
    "    rng = np.random.rand() * -2\n",
    "    return np.power(10, rng)\n",
    "\n",
    "def get_random_maxDepth(min_depth, max_depth):\n",
    "    return np.random.randint(min_depth, max_depth+1)\n",
    "\n",
    "def get_random_maxIter(min_iters, max_iters):\n",
    "    return np.random.randint(min_iters, max_iters+1)\n",
    "\n",
    "# avoids 'already exists' error\n",
    "df = df.drop(*[\"prediction\", \"probability\", \"rawPrediction\"])\n",
    "\n",
    "num_models = 40\n",
    "param_maps = [{gbt.stepSize: get_random_stepSize(),\n",
    "              gbt.maxDepth: get_random_maxDepth(3, 9),\n",
    "              gbt.maxIter: get_random_maxIter(10, 30)}\n",
    "             for i in range(num_models)]\n",
    "\n",
    "crossval = CrossValidator(estimator=gbt,\n",
    "    estimatorParamMaps=param_maps,\n",
    "    evaluator=BinaryClassificationEvaluator(),\n",
    "    numFolds=5)\n",
    "cvModel = crossval.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters tested during random search are as follows:\n",
      "stepSize 0.5271459550452572\n",
      "maxDepth 3\n",
      "maxIter 10\n",
      "Best model OOF AUC: 0.8678\n",
      "Worst model OOF AUC: 0.8175\n"
     ]
    }
   ],
   "source": [
    "bestModel = cvModel.bestModel\n",
    "best_params = {key: bestModel.extractParamMap()[key] for key in param_maps[0].keys()}\n",
    "print(\"The best parameters tested during random search are as follows:\")\n",
    "for k, v in best_params.items():\n",
    "    print(str(k).split(\"__\")[1], v)\n",
    "print(f\"Best model OOF AUC: {max(cvModel.avgMetrics):.4f}\\n\\\n",
    "Worst model OOF AUC: {min(cvModel.avgMetrics):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bestModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|  surname|\n",
      "+---------+\n",
      "|   Braund|\n",
      "|  Cumings|\n",
      "|Heikkinen|\n",
      "| Futrelle|\n",
      "|    Allen|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"surname\", regexp_extract(col(\"name\"), r\"^(\\w+)\", 0))\n",
    "df.select(\"surname\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"cabin\").distinct().count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
