{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyspark_helper.util as util\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, coalesce, col, lit, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .getOrCreate()\n",
    "\n",
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(\"train.csv\")\n",
    "\n",
    "# cheeky unpacking to turn column titles to lower\n",
    "df = df.toDF(*[c.lower() for c in df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the volume of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 891\n",
      "Column: age, num missing: 177 (% missing: 19.9%)\n",
      "Column: cabin, num missing: 687 (% missing: 77.1%)\n",
      "Column: embarked, num missing: 2 (% missing: 0.2%)\n"
     ]
    }
   ],
   "source": [
    "missing = util.print_missing(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 3/4 of Cabin data is missing (687/891). There are a total 148 unique values, so 204 of the non-missing samples are unique. There may be useful information here still (e.g. cabin area. i.e. treating A23 and A12 as equivalent). But for now, Cabin is removed.\n",
    "\n",
    "Embarked has a small amount missing. These are set these to 0 for the sake of one-hot encoding, but will have minimal effect on data. For age, a recursive tree model will be used to predict the remaining values (alternatively, simple mean could be used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that seem to offer little in terms of predictive value\n",
    "df = df.drop(\"passengerid\", \"name\", \"ticket\", \"cabin\")\n",
    "# Create a list of features\n",
    "initial_features = df.columns\n",
    "target = \"survived\"\n",
    "initial_features.remove(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns are kept where there is some a priori reason to believe they would act as strong predictors. These include:\n",
    "Pclass, Age, Sex, SibSp, Parch, Fare, Embarked\n",
    "\n",
    "Name, PassengerId, and Ticket are omitted as well due to being largely unique values without much discernible useful information\n",
    "\n",
    "Replace missing values with 0. Since these variables are categorical and 0 is not a natural value, missing data will in essence be its own category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String features for encoding: ['sex', 'embarked']\n",
      "Numeric features: ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
      "-------- Columns with null values printed below --------\n",
      "Total samples: 891\n",
      "Column: age, num missing: 177 (% missing: 19.9%)\n"
     ]
    }
   ],
   "source": [
    "# all string columns will be required to be encoded\n",
    "feature_cols_dtypes = df.dtypes\n",
    "feature_cols_dtypes.pop(0)\n",
    "features_for_encoding = [col for col, _ in feature_cols_dtypes if _ == \"string\"]\n",
    "numeric_features = [col for col, _ in feature_cols_dtypes if _ != \"string\"]\n",
    "print(\"String features for encoding: {0}\\\n",
    "\\nNumeric features: {1}\".format(features_for_encoding, numeric_features))\n",
    "df = df.na.fill(\"0\", subset=features_for_encoding)\n",
    "print(\"-\"*8, \"Columns with null values printed below\", \"-\"*8)\n",
    "missing = util.print_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one-hot transformer for Sex, Cabin, and Embarked is created and kept for use later on the test set (or during cross-validation).\n",
    "Pipeline: String -> StringIndex -> OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_transformer = util.string_to_onehot_transformer(df=df, columns_for_encoding=features_for_encoding)\n",
    "df = onehot_transformer.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, age has many missing values. Age is numerical but holds important information, so it is preferable not to drop it. The missing values can be imputed with the mean, but instead will be predicted using a simple tree model. Since this is only to fill missing data, there will not be extensive testing/cross-validating/ensembling (random forest/boosting).\n",
    "\n",
    "Below, the predictors for age are vectorised. Then, the decision tree regressor is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = numeric_features + [col+\"_encoded\" for col in features_for_encoding]\n",
    "age_predictors = feature_cols.copy()\n",
    "age_predictors.remove(\"age\")\n",
    "vectoriser = util.create_feature_vectoriser(df, age_predictors, \"age_predictors\")\n",
    "df = vectoriser.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(featuresCol=\"age_predictors\", \\\n",
    "                           labelCol=\"age\", \\\n",
    "                           predictionCol=\"age_prediction\", \\\n",
    "                           maxDepth=5)\n",
    "df_filtered = df.filter(df[\"age\"].isNotNull())\n",
    "dt_model = dt.fit(df_filtered)\n",
    "df = dt_model.transform(df)\n",
    "# df_filtered is recreated to now incorporate the prediction column for evaluation\n",
    "df_filtered = df.filter(df[\"age\"].isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the age has been predicted, its effectiveness against a simple mean impute is evaluated. RMSE is a quick metric for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of non-null values in training set: 29.70\n",
      "RMSE of predictions against training set: 11.27        \n",
      "RMSE of mean value against training set: 14.52\n"
     ]
    }
   ],
   "source": [
    "mean_age = df_filtered.agg(avg(col(\"age\"))).collect()[0][0]\n",
    "print(\"Mean of non-null values in training set: {0:.2f}\".format(mean_age))\n",
    "df_filtered = df_filtered.withColumn(\"mean_age\", lit(mean_age))\n",
    "evaluator = RegressionEvaluator()\\\n",
    "        .setMetricName(\"rmse\")\\\n",
    "        .setLabelCol(\"age\")\\\n",
    "        .setPredictionCol(\"age_prediction\")\n",
    "prediction_rmse = evaluator.evaluate(df_filtered)\n",
    "evaluator = evaluator.setPredictionCol(\"mean_age\")\n",
    "mean_rmse = evaluator.evaluate(df_filtered)\n",
    "print(\"RMSE of predictions against training set: {0:.2f}\\\n",
    "        \\nRMSE of mean value against training set: {1:.2f}\".format(prediction_rmse, mean_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not mindblowing by any means, the decision tree has reduced RMSE quite significantly from 14.52. \n",
    "\n",
    "Now all features are clean from null values. The original \"age\" column takes the prediction where \"age\" is null, and the predictors and prediction columns for age are no longer required. Then, the final features for the survival model are vectorised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"age\", coalesce(df.age, df.age_prediction))\n",
    "df = df.drop(\"age_predictors\", \"age_prediction\")\n",
    "feature_vectoriser = util.create_feature_vectoriser(df, feature_cols, \"features\")\n",
    "df = feature_vectoriser.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Columns to be used as features\n",
      "['pclass', 'age', 'sibsp', 'parch', 'fare', 'sex_encoded', 'embarked_encoded'] \n",
      "\n",
      "-------- Top 5 rows of label and vectorised features\n",
      "+--------+--------------------+\n",
      "|survived|            features|\n",
      "+--------+--------------------+\n",
      "|       0|[3.0,22.0,1.0,0.0...|\n",
      "|       1|[1.0,38.0,1.0,0.0...|\n",
      "|       1|(9,[0,1,4,6],[3.0...|\n",
      "|       1|[1.0,35.0,1.0,0.0...|\n",
      "|       0|[3.0,35.0,0.0,0.0...|\n",
      "+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*8, f\"Columns to be used as features\")\n",
    "print(feature_cols, \"\\n\")\n",
    "print(\"-\"*8, \"Top 5 rows of label and vectorised features\")\n",
    "df.select(\"survived\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+-----+-------+-------------+----------------+\n",
      "|pclass| age|sibsp|parch|   fare|  sex_encoded|embarked_encoded|\n",
      "+------+----+-----+-----+-------+-------------+----------------+\n",
      "|     3|22.0|    1|    0|   7.25|(1,[0],[1.0])|   (3,[0],[1.0])|\n",
      "|     1|38.0|    1|    0|71.2833|    (1,[],[])|   (3,[1],[1.0])|\n",
      "|     3|26.0|    0|    0|  7.925|    (1,[],[])|   (3,[0],[1.0])|\n",
      "|     1|35.0|    1|    0|   53.1|    (1,[],[])|   (3,[0],[1.0])|\n",
      "|     3|35.0|    0|    0|   8.05|(1,[0],[1.0])|   (3,[0],[1.0])|\n",
      "+------+----+-----+-----+-------+-------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*feature_cols).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note AUC will be used as the evaluation metric, so thresholds are not a concern. Model will be first run with the base hyperparameters before performing random (as opposed to grid) search with 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"survived\", \"label\")\n",
    "\n",
    "# df = df.drop(*[\"prediction\", \"probability\", \"rawPrediction\"]) # uncomment when testing\n",
    "\n",
    "gbt = GBTClassifier()\n",
    "\n",
    "gbt_transformer = gbt.fit(df)\n",
    "df = gbt_transformer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+--------------------+\n",
      "|label|prediction|         probability|       rawPrediction|\n",
      "+-----+----------+--------------------+--------------------+\n",
      "|    0|       0.0|[0.91398813051760...|[1.18166614054903...|\n",
      "|    1|       1.0|[0.05278475052523...|[-1.4436520151715...|\n",
      "|    1|       1.0|[0.48663789379179...|[-0.0267305771414...|\n",
      "|    1|       1.0|[0.04441291376077...|[-1.5343978119854...|\n",
      "|    0|       0.0|[0.88634908728346...|[1.02698964775194...|\n",
      "+-----+----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Incorrect predictions: 91\n",
      "0.9542655972049133\n"
     ]
    }
   ],
   "source": [
    "df.select(*[\"label\", \"prediction\", \"probability\", \"rawPrediction\"]).show(5)\n",
    "print(\"Incorrect predictions:\",df.filter(df.label != df.prediction).count())\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print(evaluator.evaluate(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has very high AUC. Even with the default threshold of 0.5, it is only inaccurate for 91 rows... But it is obviously overfitting. Time for cross validation and random parameter search. The final parameters will be those which maximise the OOF metric (AUC).\n",
    "\n",
    "Note that below, the paramGrid is not actually a grid and only offers one option per hyperparameter. This is because the intention is to perform random search rather than grid search. There may be a more elegant solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few temporary functions are defined:\n",
    "get_random_lr returns a random learning rate, reasonably between 0.01 and 1 (using negative log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_stepSize():\n",
    "    rng = np.random.rand() * -2\n",
    "    return np.power(10, rng)\n",
    "\n",
    "def get_random_maxDepth(min_depth, max_depth):\n",
    "    return np.random.randint(min_depth, max_depth+1)\n",
    "\n",
    "def get_random_maxIter(min_iters, max_iters):\n",
    "    return np.random.randint(min_iters, max_iters+1)\n",
    "\n",
    "df = df.drop(*[\"prediction\", \"probability\", \"rawPrediction\"])\n",
    "\n",
    "num_models = 20\n",
    "models = []\n",
    "param_maps = []\n",
    "for i in range(num_models):\n",
    "    stepSize = get_random_stepSize()\n",
    "    maxDepth = get_random_maxDepth(3, 8)\n",
    "    maxIter = get_random_maxIter(10, 30)\n",
    "    param_maps.append(ParamGridBuilder()\\\n",
    "            .addGrid(gbt.stepSize, [stepSize])\\\n",
    "            .addGrid(gbt.maxDepth, [maxDepth])\\\n",
    "            .addGrid(gbt.maxIter, [maxIter])\\\n",
    "            .build()[0])\n",
    "\n",
    "crossval = CrossValidator(estimator=gbt,\n",
    "    estimatorParamMaps=param_maps,\n",
    "    evaluator=BinaryClassificationEvaluator(),\n",
    "    numFolds=5)\n",
    "cvModel = crossval.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Param(parent='GBTClassifier_5f83beb35ae7', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(param_maps[0].keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = cvModel.bestModel\n",
    "bestModel_params = bestModel.extractParamMap()\n",
    "best_params_dict = {}\n",
    "for key in param_maps[0].keys():\n",
    "    best_params_dict[key] = bestModel_params[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBTClassifier_5f83beb35ae7__stepSize 0.09811242482588277\n",
      "GBTClassifier_5f83beb35ae7__maxDepth 5\n",
      "GBTClassifier_5f83beb35ae7__maxIter 24\n"
     ]
    }
   ],
   "source": [
    "for k,v in best_params_dict.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst model AUC: 0.84\n",
      "    Best model AUC: 0.87\n"
     ]
    }
   ],
   "source": [
    "print(f\"Worst model AUC: {min(cvModel.avgMetrics):.2f}\\n\\\n",
    "    Best model AUC: {max(cvModel.avgMetrics):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
